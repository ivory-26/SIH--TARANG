#!/usr/bin/env python3\n\"\"\"\nFloat-Chat-AI Prototype Test Script\n\nThis script demonstrates the key functionality of the Float-Chat-AI prototype.\n\"\"\"\n\nimport asyncio\nimport sys\nimport os\n\n# Add the backend to the path\nsys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))\n\nfrom services.data_processor import DataProcessor\nfrom services.ai_service import AIService\nfrom services.database import DatabaseService\n\nasync def test_data_processor():\n    \"\"\"Test the data processing pipeline\"\"\"\n    print(\"\\n🌊 Testing Data Processing Pipeline\")\n    print(\"=\" * 50)\n    \n    processor = DataProcessor()\n    \n    # Test mock data generation\n    print(\"📊 Loading/generating mock ARGO data...\")\n    dataset = await processor.load_netcdf_data()\n    print(f\"✅ Dataset loaded with variables: {list(dataset.data_vars.keys())}\")\n    print(f\"   Dimensions: {dict(dataset.dims)}\")\n    \n    # Test query execution\n    sample_queries = [\n        {'variable': 'TEMP', 'operation': 'mean'},\n        {'variable': 'PSAL', 'operation': 'max'},\n        {'variable': 'TEMP', 'operation': 'profile'}\n    ]\n    \n    for query in sample_queries:\n        result = await processor.execute_query(query)\n        if result['success']:\n            print(f\"✅ Query: {query['variable']} {query['operation']}\")\n            print(f\"   Result: {result['description']}\")\n            if isinstance(result['data'], (int, float)):\n                print(f\"   Value: {result['data']:.2f} {result['metadata']['units']}\")\n        else:\n            print(f\"❌ Query failed: {result['error']}\")\n\nasync def test_ai_service():\n    \"\"\"Test the AI service functionality\"\"\"\n    print(\"\\n🤖 Testing AI Service Pipeline\")\n    print(\"=\" * 50)\n    \n    ai_service = AIService()\n    \n    # Test query parsing\n    test_queries = [\n        \"What's the average temperature?\",\n        \"Show me a salinity profile\", \n        \"Find the maximum temperature at 1000 meters\",\n        \"What's the pressure data?\"\n    ]\n    \n    for query in test_queries:\n        print(f\"\\n🔍 Processing: '{query}'\")\n        parsed = await ai_service.parse_query(query)\n        print(f\"   Parsed as: {parsed}\")\n        \n        # Mock data result for response generation\n        mock_data_result = {\n            'success': True,\n            'data': 15.3,\n            'metadata': {'variable': parsed['variable'], 'units': '°C'},\n            'description': f\"Average {parsed['variable']}\"\n        }\n        \n        response = await ai_service.generate_response(query, mock_data_result, parsed)\n        print(f\"   AI Response: {response}\")\n\nasync def test_database_service():\n    \"\"\"Test the database service\"\"\"\n    print(\"\\n💾 Testing Database Service\")\n    print(\"=\" * 50)\n    \n    db_service = DatabaseService()\n    \n    # Test session management\n    session_id = \"test_session_123\"\n    query_id = await db_service.save_query_history(\n        session_id, \n        \"What's the temperature?\", \n        \"The average temperature is 15.3°C\",\n        {'data': 15.3, 'success': True}\n    )\n    print(f\"✅ Saved query with ID: {query_id}\")\n    \n    # Test history retrieval\n    history = await db_service.get_session_history(session_id)\n    print(f\"✅ Retrieved {len(history)} items from session history\")\n    \n    if history:\n        print(f\"   Latest query: {history[0]['user_query']}\")\n        print(f\"   AI response: {history[0]['ai_response']}\")\n\nasync def test_end_to_end():\n    \"\"\"Test the complete pipeline\"\"\"\n    print(\"\\n🚀 End-to-End Pipeline Test\")\n    print(\"=\" * 50)\n    \n    # Initialize services\n    processor = DataProcessor()\n    ai_service = AIService()\n    db_service = DatabaseService()\n    \n    # Simulate a complete user query\n    user_query = \"What's the average temperature at 500 meters depth?\"\n    session_id = \"test_e2e_session\"\n    \n    print(f\"👤 User Query: '{user_query}'\")\n    \n    # Step 1: Parse query\n    parsed_query = await ai_service.parse_query(user_query)\n    print(f\"🧠 Parsed Query: {parsed_query}\")\n    \n    # Step 2: Execute data processing\n    data_result = await processor.execute_query(parsed_query)\n    print(f\"📊 Data Result: {data_result['description'] if data_result['success'] else data_result['error']}\")\n    \n    # Step 3: Generate AI response\n    ai_response = await ai_service.generate_response(user_query, data_result, parsed_query)\n    print(f\"🤖 AI Response: {ai_response}\")\n    \n    # Step 4: Save to database\n    query_id = await db_service.save_query_history(session_id, user_query, ai_response, data_result)\n    print(f\"💾 Saved to database with ID: {query_id}\")\n    \n    # Step 5: Create visualization (if applicable)\n    if data_result['success'] and data_result.get('data'):\n        viz = await processor.create_visualization(data_result['data'], parsed_query.get('viz_type', 'table'))\n        if viz:\n            print(f\"📈 Visualization: {viz['type']} created\")\n        else:\n            print(\"📊 No visualization generated\")\n    \n    print(\"\\n✅ End-to-end pipeline completed successfully!\")\n\nasync def main():\n    \"\"\"Main test function\"\"\"\n    print(\"🌊 Float-Chat-AI Prototype Test Suite\")\n    print(\"=====================================\")\n    print(\"Testing the conversational AI interface for oceanographic data\")\n    \n    try:\n        await test_data_processor()\n        await test_ai_service()\n        await test_database_service()\n        await test_end_to_end()\n        \n        print(\"\\n🎉 All tests completed successfully!\")\n        print(\"\\n📋 Summary:\")\n        print(\"   ✅ Data processing with mock ARGO data\")\n        print(\"   ✅ AI-powered natural language query parsing\")\n        print(\"   ✅ Conversational response generation\")\n        print(\"   ✅ Session management and history\")\n        print(\"   ✅ End-to-end pipeline integration\")\n        print(\"\\n🚀 The Float-Chat-AI prototype is working correctly!\")\n        \n    except Exception as e:\n        print(f\"\\n❌ Test failed with error: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return 1\n    \n    return 0\n\nif __name__ == \"__main__\":\n    exit_code = asyncio.run(main())